import os
from typing import List
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_chroma import Chroma

# S·ª≠a l·ªói ModuleNotFoundError: Tr·ªè tr·ª±c ti·∫øp v√†o ƒë∆∞·ªùng d·∫´n m·ªõi nh·∫•t
from langchain.chains.retrieval import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

from langchain_core.prompts import ChatPromptTemplate
from app.core.config import settings

class RAGService:
    def __init__(self):
        # Kh·ªüi t·∫°o AI v√† Embeddings
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001", 
            google_api_key=settings.GOOGLE_API_KEY
        )
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash", 
            google_api_key=settings.GOOGLE_API_KEY, 
            temperature=0.3
        )
        # Kh·ªüi t·∫°o Vector Store v·ªõi t√≠nh nƒÉng l∆∞u tr·ªØ vƒ©nh vi·ªÖn
        self.vector_store = Chroma(
            persist_directory=settings.DATABASE_DIR,
            embedding_function=self.embeddings
        )

    def ingest_documents(self, directory_path: str):
        """Nhi·ªám v·ª• Tu·∫ßn 2: X·ª≠ l√Ω PDF v√† Metadata"""
        documents = []
        if not os.path.exists(directory_path):
            print(f"L·ªói: Th∆∞ m·ª•c {directory_path} kh√¥ng t·ªìn t·∫°i.")
            return

        for filename in os.listdir(directory_path):
            if filename.endswith(".pdf"):
                file_path = os.path.join(directory_path, filename)
                loader = PyPDFLoader(file_path)
                # loader.load() t·ª± ƒë·ªông g√°n metadata l√† t√™n file v√† s·ªë trang
                docs = loader.load()
                documents.extend(docs)
                print(f"‚úÖ ƒê√£ n·∫°p: {filename}")

        if not documents:
            print("‚ùå Kh√¥ng t√¨m th·∫•y t√†i li·ªáu n√†o.")
            return

        # Nhi·ªám v·ª• Tu·∫ßn 2: Chunking khoa h·ªçc
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, 
            chunk_overlap=200,
            separators=["\n\n", "\n", ".", " ", ""] # Ng·∫Øt c√¢u th√¥ng minh
        )
        splits = text_splitter.split_documents(documents)
        
        # Nhi·ªám v·ª• Tu·∫ßn 3: ƒê·∫©y v√†o Vector DB
        self.vector_store.add_documents(documents=splits)
        print(f"üöÄ ƒê√£ s·ªë h√≥a {len(splits)} ƒëo·∫°n vƒÉn b·∫£n v√†o ChromaDB.")

    def ask_question(self, question: str) -> str:
        """Nhi·ªám v·ª• Tu·∫ßn 4: Truy v·∫•n th√¥ng minh"""
        # Retrieval: L·∫•y 5 ƒëo·∫°n li√™n quan nh·∫•t
        retriever = self.vector_store.as_retriever(search_kwargs={"k": 5})
        
        # System Prompt chuy√™n nghi·ªáp cho tr∆∞·ªùng h·ªçc
        system_prompt = (
            "B·∫°n l√† tr·ª£ l√Ω ·∫£o h·ªó tr·ª£ sinh vi√™n d·ª±a tr√™n t√†i li·ªáu n·ªôi b·ªô c·ªßa nh√† tr∆∞·ªùng. "
            "Ch·ªâ s·ª≠ d·ª•ng c√°c ƒëo·∫°n vƒÉn b·∫£n d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi. "
            "N·∫øu th√¥ng tin kh√¥ng c√≥ trong t√†i li·ªáu, h√£y n√≥i 'T√¥i kh√¥ng bi·∫øt'. "
            "C√¢u tr·∫£ l·ªùi c·∫ßn ng·∫Øn g·ªçn, ch√≠nh x√°c v√† l·ªãch s·ª±."
            "\n\n"
            "{context}"
        )

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}"),
        ])

        # K·∫øt n·ªëi c√°c m·∫£nh gh√©p RAG
        question_answer_chain = create_stuff_documents_chain(self.llm, prompt)
        rag_chain = create_retrieval_chain(retriever, question_answer_chain)

        response = rag_chain.invoke({"input": question})
        return response["answer"]

rag_service = RAGService()